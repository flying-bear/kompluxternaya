{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flying-bear/kompluxternaya/blob/master/assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THlw8AQ5Gp7-",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "1. Implement Logistic Regression with Stochastic Gradient Decent using numpy\n",
        "1. Implement Logistic Regression with early stopping using pytorch\n",
        "\n",
        "Additional readings:\n",
        "1. https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html\n",
        "1. https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmmeezcRGp8C",
        "colab_type": "code",
        "outputId": "294220a6-257b-4e0f-d9a3-0cd7a48a4307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"error\")\n",
        "\n",
        "# retrieve dataset\n",
        "data = fetch_20newsgroups()\n",
        "\n",
        "\n",
        "X_train = data['data']\n",
        "y_train = data['target']\n",
        "\n",
        "tfidf = TfidfVectorizer(max_df=0.5, min_df=10)\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "\n",
        "test_data = fetch_20newsgroups(subset='test')\n",
        "X_test = tfidf.transform(test_data['data'])\n",
        "y_test = test_data['target']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj2mr-g9Gp8G",
        "colab_type": "text"
      },
      "source": [
        "## 1 Binary Logistic Regression\n",
        "$\\{(x_i, y_i)\\}_{i=1}^N$, $y \\in \\{0,1\\}$\n",
        "$$ z = Xw + b $$\n",
        "\n",
        "$$p(y=1 | x) = \\sigma(z) = \\frac 1 {1 + e^{-z}}$$\n",
        "\n",
        "$$ L_{batch} = - \\frac 1 {|batch|} \\sum_{i \\in batch}^N [ y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i)) ] + \\frac \\lambda 2 w^T w$$\n",
        "\n",
        "Stochastic Gradient Decent for logreg:\n",
        "1. init w ~ random N(0,1), b = 0\n",
        "1. for epoch = 1..n_epochs:\n",
        "    * shuffle dataset\n",
        "    * for every batch:\n",
        "        * $w^{(t)} \\leftarrow w^{(t-1)} - \\alpha \\nabla_{w} L_{batch}(w^{(t-1)},b^{(t-1)})$\n",
        "        * $b^{(t)} \\leftarrow b^{(t-1)} - \\alpha \\nabla_{b} L_{batch}(w^{(t-1)},b^{(t-1)})$\n",
        "        \n",
        "$w$ - weights  \n",
        "$b$ - biases  \n",
        "$\\alpha$ - learning rate\n",
        "\n",
        "Hint:\n",
        "$$\\nabla_w L = \\frac {\\partial L} {\\partial \\sigma} \\frac {\\partial \\sigma} {\\partial z} \\frac {\\partial z} {\\partial w} + \\frac {\\partial (\\frac \\lambda 2 w^T w)} {\\partial w} $$\n",
        "$$\\nabla_b L = \\frac {\\partial L} {\\partial \\sigma} \\frac {\\partial \\sigma} {\\partial z} \\frac {\\partial z} {\\partial b} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO3tY0n7Gp8H",
        "colab_type": "code",
        "outputId": "302f1d87-ee37-4ada-cc54-3f66a4f9ba2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# make dataset for binary classification\n",
        "\n",
        "X_train_bin = X_train[y_train < 2]\n",
        "y_train_bin = y_train[y_train < 2]\n",
        "\n",
        "X_test_bin = X_test[y_test < 2]\n",
        "y_test_bin = y_test[y_test < 2]\n",
        "\n",
        "y_train_bin.shape, y_test_bin.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1064,), (708,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM9I_3xjT-dk",
        "colab_type": "code",
        "outputId": "37a4ab41-c1d7-4a3b-cfcc-9d2bbc6ba0e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(f'X shape: {X_train_bin.shape}')\n",
        "print(f'y shape: {y_train_bin.shape}')\n",
        "w_test_size = np.random.randn(X_train_bin.shape[1])\n",
        "print(f'w shape: {w_test_size.shape}')\n",
        "print(f'Xw shape: {(X_train_bin.dot(w_test_size)).shape}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (1064, 15566)\n",
            "y shape: (1064,)\n",
            "w shape: (15566,)\n",
            "Xw shape: (1064,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwRvEA7FNAuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRY TO IMPLEMENT LOSS on some 64 datapoints\n",
        "\n",
        "llambda = 1\n",
        "test_batch_X = X_train_bin[64:128, :]\n",
        "test_batch_y = y_train_bin[64:128]\n",
        "w = np.random.randn(test_batch_X.shape[1])\n",
        "b = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLm5RnH2z6aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_loss(batch_X, batch_y, w, b, llambda, batch_size):\n",
        "  z = batch_X.dot(w) + b\n",
        "  sigm = 1 / (1 + np.exp(-z))\n",
        "  loss = (-1/batch_size) * (np.sum(batch_y*np.log(sigm) + (1-batch_y)*(np.log(1-sigm)))).item() + (llambda/2) * w.transpose().dot(w)\n",
        "  return loss, sigm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEN0XYuQ0IbK",
        "colab_type": "code",
        "outputId": "40941ef6-84fd-4136-b00e-c28a3001b4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss, test_sigm = count_loss(test_batch_X, test_batch_y, w, b, llambda, test_batch_y.shape[0])\n",
        "test_loss"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7720.703435849736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IanngQfVr8T7",
        "colab_type": "text"
      },
      "source": [
        "**Gradient formulae**\n",
        "\n",
        "$$\\nabla_w L = \\frac {\\partial L} {\\partial \\sigma} \\frac {\\partial \\sigma} {\\partial z} \\frac {\\partial z} {\\partial w} + \\frac {\\partial (\\frac \\lambda 2 w^T w)} {\\partial w} $$\n",
        "$$\\nabla_b L = \\frac {\\partial L} {\\partial \\sigma} \\frac {\\partial \\sigma} {\\partial z} \\frac {\\partial z} {\\partial b} $$\n",
        "\n",
        "Посчитаем части формул\n",
        "$$ L_{batch} = - \\frac 1 {|batch|} \\sum_{i \\in batch}^N [ y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i)) ] + \\frac \\lambda 2 w^T w$$\n",
        "\n",
        "$$\\frac {\\partial} {\\partial \\sigma}[y \\log \\sigma(z) + (1 - y) \\log (1 - \\sigma(z))] = \\frac {y}{\\sigma} + \\frac {-1 \\cdot (1 - y)}{1 - \\sigma} = \\frac {y(1 - \\sigma) - \\sigma(1 - y)} {\\sigma(1 - \\sigma)} = \\frac {y - \\sigma y - \\sigma + \\sigma y}{\\sigma(1 - \\sigma)} = \\frac {y - \\sigma}{\\sigma(1 - \\sigma)}$$\n",
        "\n",
        "$$\\frac {\\partial L} {\\partial \\sigma} = -\\frac {1} {|batch|} \\sum_{i \\in batch}^N \\frac {y_i - \\sigma(z_i)} {\\sigma (1 - \\sigma(z_i))}$$\n",
        "\n",
        "$$\\frac {\\partial \\sigma} {\\partial z} = \\frac 1 {1 + e^{-z}} \\frac {e^{-z}} {(1 + e^{-z})^2} ={\\sigma}({1 - \\sigma})$$\n",
        "\n",
        "$$ \\frac {\\partial z} {\\partial w} = X^T $$\n",
        "\n",
        "$$ \\frac {\\partial (\\frac \\lambda 2 w^T w)} {\\partial w} = \\lambda w$$\n",
        "\n",
        "$$ \\frac {\\partial z} {\\partial b} = 1 $$\n",
        "Identity matrix\n",
        "\n",
        "\n",
        "Соберём вместе\n",
        "\n",
        "$$\\nabla_w L = \\frac {- \\sigma (1 - \\sigma) X^T} {|batch|} \\sum_{i \\in batch}^N [\\frac {y_i - \\sigma_i} {\\sigma_i (1 - \\sigma_i)}] +  \\lambda w$$\n",
        "$$\\nabla_b L = \\frac {-\\sigma (1 - \\sigma)} {|batch|} \\sum_{i \\in batch}^N [\\frac {y_i - \\sigma_i} {\\sigma_i (1 - \\sigma_i)}]$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjgsEj7Ercgz",
        "colab_type": "code",
        "outputId": "0a891705-9724-4061-b343-a835a4cda434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# TRY TO IMPLEMENT GRADIENT\n",
        "batch_size = test_batch_y.shape[0]\n",
        "test_dL_dsigm = (-1/batch_size) * np.sum((test_batch_y - test_sigm)/(test_sigm * (1-test_sigm)))\n",
        "test_dsigm_dz = test_sigm * (1 - test_sigm)\n",
        "test_grad_w = test_dL_dsigm * test_batch_X.transpose().dot(test_dsigm_dz) + llambda * w\n",
        "test_grad_b = test_dL_dsigm * test_dsigm_dz.dot(np.ones(test_dsigm_dz.shape[0]))\n",
        "\n",
        "test_grad_w.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15566,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4-KnRhSJ8pU",
        "colab_type": "code",
        "outputId": "b2c5ead4-029b-48e6-9d59-1bf98237b37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# COMPARE LOSS BEFORE AND AFTER SGD\n",
        "print(count_loss(test_batch_X, test_batch_y, w, b, llambda, test_batch_y.shape[0])[0])\n",
        "print(count_loss(test_batch_X, test_batch_y, w-0.0001*test_grad_w, b-0.0001*test_grad_b, llambda, test_batch_y.shape[0])[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7720.703435849736\n",
            "7719.159517404813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImY3_9veLPZr",
        "colab_type": "text"
      },
      "source": [
        "[gradient checking](https://datascience-enthusiast.com/DL/Improving_DeepNeural_Networks_Gradient_Checking.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJehL2W4Gp8L",
        "colab_type": "code",
        "outputId": "bbe0dbce-8502-4406-ea6a-b7f4d36b47d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "\n",
        "class LogRegNumpy(ClassifierMixin):\n",
        "    def __init__(self, llambda=1, lr=0.0001, batch_size=32, n_epochs=100):\n",
        "        \"\"\"\n",
        "        llambda: regularization strength\n",
        "        lr: learning rate\n",
        "        \"\"\"\n",
        "        self.w = None\n",
        "        self.b = 0\n",
        "        self.llambda = llambda\n",
        "        self.n_epochs = n_epochs\n",
        "        self.lr = lr\n",
        "        self.history = []\n",
        "        self.batch_size = batch_size\n",
        "       \n",
        "    def fit(self, X, y):\n",
        "        self.w = np.random.randn(X.shape[1])\n",
        "        self.b = 0\n",
        "        \n",
        "        for epoch in range(self.n_epochs):\n",
        "            \n",
        "            # random permutation over indices of dataset\n",
        "            batch_indices = np.random.permutation(len(y))\n",
        "            \n",
        "            for j in range(0, len(y), self.batch_size):\n",
        "                batch_idx = batch_indices[j:j+self.batch_size]\n",
        "                batch_X = X[batch_idx]\n",
        "                batch_y = y[batch_idx]\n",
        "            \n",
        "                # forward pass\n",
        "                # <TODO> [1 point] calculate batch loss\n",
        "                def batch_loss(batch_X, batch_y, w, b, llambda, batch_size):\n",
        "                  \"\"\"\n",
        "                  calculates loss over a batch with regularization\n",
        "                  :param batch_X: batch data, np.ndarray of shape (batch size, number of features)\n",
        "                  :param batch_y: batch labels, np.ndarray of shape (batch size,)\n",
        "                  :param w: weigths matrix, np.ndarray of shape (number of features,)\n",
        "                  :param b: bias, a number (int or float)\n",
        "                  :param llambda: regularizartion strength, a number (int or float)\n",
        "                  :param batch_size: batch size, int\n",
        "\n",
        "                  :return loss: loss, float\n",
        "                  :return sigm: predictions, np.ndarray of shape (batch size,)\n",
        "                  :return z: sigmoid logit, np.ndarray of shape (batch size,)\n",
        "                  \"\"\"\n",
        "                  z = batch_X.dot(w) + b\n",
        "                  # if np.isnan(np.sum(z)):\n",
        "                  #   return\n",
        "                  sigm = 1 / (1 + np.exp(-z))\n",
        "                  reg = (llambda/2) * w.transpose().dot(w)\n",
        "                  loss = (-1/batch_size) * (np.sum(batch_y*np.log(sigm) + (1-batch_y)*(np.log(1-sigm)))).item() + reg\n",
        "                  return loss, sigm, z\n",
        "                loss, sigm, z = batch_loss(batch_X, batch_y, self.w, self.b, self.llambda, self.batch_size)\n",
        "\n",
        "                # backward pass\n",
        "                # <TODO> [2 points] calculate batch gradients \n",
        "                dL_dsigm = (-1/self.batch_size) * np.sum((batch_y - sigm)/(sigm * (1-sigm)))\n",
        "                dsigm_dz = sigm * (1 - sigm)\n",
        "                grad_w = dL_dsigm * batch_X.transpose().dot(dsigm_dz) + self.llambda * self.w\n",
        "                grad_b = dL_dsigm * dsigm_dz.dot(np.ones(dsigm_dz.shape[0]))\n",
        "\n",
        "                # # check gradient of b\n",
        "                # epsilon = 1e-7  # (is this epsilon small enough?)\n",
        "                # b_minus_step_loss = batch_loss(batch_X, batch_y, self.w, self.b-epsilon, self.llambda, self.batch_size)[0]\n",
        "                # b_plus_step_loss = batch_loss(batch_X, batch_y, self.w, self.b+epsilon, self.llambda, self.batch_size)[0]\n",
        "                # approximate_grad_b = (b_plus_step_loss - b_minus_step_loss)/ (2*epsilon)\n",
        "                # print(grad_b, approximate_grad_b)\n",
        "                # b_difference = abs(grad_b-approximate_grad_b)/(abs(grad_b)+abs(approximate_grad_b))\n",
        "                # assert b_difference < epsilon, f\"approximated gradient for b differs from calculated by {b_difference}\"\n",
        "\n",
        "                # # check gradient of w\n",
        "                # param_num = self.w.shape[0]\n",
        "                # w_plus_step_loss = np.zeros(param_num)\n",
        "                # w_minus_step_loss = np.zeros(param_num)\n",
        "                # approximate_grad_w = np.zeros(param_num)\n",
        "                # for i in range(param_num):\n",
        "                #   check_w_plus = np.copy(self.w)\n",
        "                #   check_w_plus[i] += epsilon\n",
        "                #   w_plus_step_loss[i] = batch_loss(batch_X, batch_y, check_w_plus, self.b, self.llambda, self.batch_size)[0]\n",
        "\n",
        "                #   check_w_minus = np.copy(self.w)\n",
        "                #   check_w_minus[i] -= epsilon\n",
        "                #   w_minus_step_loss[i] = batch_loss(batch_X, batch_y, check_w_minus, self.b, self.llambda, self.batch_size)[0]\n",
        "\n",
        "                #   approximate_grad_w[i] = (w_plus_step_loss[i] - w_minus_step_loss[i]) / (2 * epsilon)\n",
        "                # w_difference = np.linalg.norm(grad_w - approximate_grad_w) / (np.linalg.norm(grad_w) + np.linalg.norm(approximate_grad_w))\n",
        "                # assert w_difference < epsilon,  f\"approximated gradient for w differs from calculated by {w_difference}\"\n",
        "\n",
        "                # SGD optimization step\n",
        "                # <TODO> [1 point]\n",
        "                self.w -= self.lr * grad_w\n",
        "                self.b -= self.lr * grad_b\n",
        "                \n",
        "                self.history.append(loss)\n",
        "        \n",
        "        return self \n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        # <TODO> [1 point] calculate p(y=1 | x)\n",
        "        z = X.dot(self.w) + self.b\n",
        "        p = 1 / (1 + np.exp(-z))\n",
        "        return p\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return (self.predict_proba(X) > 0.5).astype(np.int)\n",
        "    \n",
        "    \n",
        "model = LogRegNumpy(llambda = 3, lr=0.001, batch_size=128, n_epochs=100)\n",
        "model.fit(X_train_bin, y_train_bin)\n",
        "print('auc', metrics.roc_auc_score(y_test_bin, model.predict_proba(X_test_bin)))\n",
        "\n",
        "plt.plot(np.arange(len(model.history)), model.history)\n",
        "plt.xlabel('iters')\n",
        "plt.ylabel('train loss');"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc 0.5701058094462934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl7PqSm-Gp8N",
        "colab_type": "text"
      },
      "source": [
        "# Multinomial Logistic Regression using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2NVfSdgGp8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5a0uBhBGp8Q",
        "colab_type": "text"
      },
      "source": [
        "###  [1 point] implement linear model $Z = XW + b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TUHTCONGp8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogRegNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_features, n_classes):\n",
        "        super(LogRegNN, self).__init__()\n",
        "        \n",
        "        # create tensor of weights and tensor of biases\n",
        "        # initialize tensors from N(0,1) \n",
        "        # W has shape (n_features, n_classes)\n",
        "        # b has shape (n_classes,)\n",
        "        self.W = nn.Parameter(torch.randn(n_features, n_classes))\n",
        "        self.b = nn.Parameter(torch.randn(n_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In this method we implement connections between neural network weights\n",
        "        x: batch feature matrix\n",
        "        returns: probability logits\n",
        "        \"\"\"\n",
        "        # <TODO> implement linear model \n",
        "        x_dense = torch.from_numpy(x.todense())\n",
        "        result = torch.mm(x_dense, self.W) + self.b\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IchAOQJHAFdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "3fbb2ace-4a7f-49c2-fe6e-43ff6bb35f7a"
      },
      "source": [
        "model = LogRegNN(X_train.shape[1], 20)\n",
        "model(test_batch_X)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-d706a180e0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogRegNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-e58ef3755f73>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# <TODO> implement linear model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for argument #2 'mat2' in call to _th_mm"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOTIaY_ZGp8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(model, batch_x, batch_y):\n",
        "    # set NN model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass\n",
        "    pred = model(batch_x)\n",
        "    # cross-entropy loss\n",
        "    loss = criterion(pred, batch_y)\n",
        "    # calculate gradients\n",
        "    loss.backward()\n",
        "    # make optimization step\n",
        "    optimizer.step()\n",
        "    \n",
        "    # return batch loss\n",
        "    return loss.data.detach().item()\n",
        "\n",
        "def eval_batch(model, batch_x, batch_y):\n",
        "    # set NN model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # forward pass\n",
        "        pred = model(batch_x)\n",
        "        # cross-entropy loss\n",
        "        loss = criterion(pred, batch_y)\n",
        "\n",
        "    # return batch loss\n",
        "    return loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcZKcQ1BGp8V",
        "colab_type": "text"
      },
      "source": [
        "### [2 points] implement early stopping using early_stopping_patience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUUpVo6x-vp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import reduce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmYimmWXGp8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, valid_loader, n_epochs, early_stopping_patience=5):\n",
        "    \"\"\"\n",
        "    early_stopping_patience - number of consecutive epochs of growing validation loss to wait\n",
        "    \"\"\"\n",
        "    history = {'train': [], 'valid': []}\n",
        "\n",
        "    # <TODO> implement early stopping using early_stopping_patience\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        # iterate over batches\n",
        "        for batch_x, batch_y in tqdm(train_loader, desc=f'epoch:{epoch}', leave=True):\n",
        "\n",
        "            loss = train_batch(model, batch_x, batch_y)\n",
        "            epoch_train_loss += loss\n",
        "\n",
        "        # average loss for epoch\n",
        "        epoch_train_loss /= len(train_loader)\n",
        "        history['train'].append(epoch_train_loss)\n",
        "        \n",
        "        epoch_valid_loss = 0\n",
        "        for batch_x, batch_y in valid_loader:\n",
        "            loss = eval_batch(model, batch_x, batch_y)\n",
        "            epoch_valid_loss += loss\n",
        "            \n",
        "        epoch_valid_loss /= len(valid_loader)\n",
        "        print(f'train loss: {epoch_train_loss:.3f} valid loss:{epoch_valid_loss:.3f}')\n",
        "        history['valid'].append(epoch_valid_loss)\n",
        "        \n",
        "        # <TODO> implement early stopping using early_stopping_patience\n",
        "        if len(history['valid']) > early_stopping_patience:\n",
        "          if reduce(lambda x, y: x < y, history['valid'][-early_stopping_patience:]):\n",
        "            return history \n",
        "\n",
        "    return history "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv0-cG9qGp8X",
        "colab_type": "text"
      },
      "source": [
        "### predict hard labels [1 point]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7lhvAsHGp8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, test_loader):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    result = []\n",
        "    with torch.no_grad():\n",
        "        for batch_x in test_loader:\n",
        "            # <TODO> predict hard labels\n",
        "            pred = \n",
        "            result.append(pred)\n",
        "    return np.concatenate(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-pN2aPbGp8a",
        "colab_type": "text"
      },
      "source": [
        "DataLoader implements iteration over batches and shuffling\n",
        "\n",
        "L2 regularization coef is embedded into SGD.weight_decay: \n",
        "\n",
        "1. $w^{(t-1)} \\leftarrow w^{(t-2)} - \\alpha \\lambda w^{(t-2)} $  \n",
        "1. $w^{(t)} \\leftarrow w^{(t-1)} - \\alpha \\nabla_{w} L(w^{(t-1)}) $\n",
        "\n",
        "here   \n",
        "$\\alpha$ - learning rate  \n",
        "$\\lambda$ - weight-decay = L2 regularization coef"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbBkftMcGp8a",
        "colab_type": "code",
        "outputId": "a8013d27-5fd1-4589-c19c-4c260771da3e",
        "colab": {}
      },
      "source": [
        "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_train, y_train, stratify=y_train,\n",
        "                                                      shuffle=True, test_size=0.2, random_state=42)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(torch.tensor(X_train2.todense()).float(), torch.tensor(y_train2).long()), \n",
        "                          batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(TensorDataset(torch.tensor(X_valid2.todense()).float(), torch.tensor(y_valid2).long()), \n",
        "                          batch_size=batch_size)\n",
        "test_loader = DataLoader(torch.tensor(X_test.todense()).float(), \n",
        "                          batch_size=batch_size)\n",
        "\n",
        "model = LogRegNN(X_train.shape[1], 20)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# L2 regularization is embeded in \n",
        "optimizer = optim.SGD(model.parameters(), lr=10.0, weight_decay=0.0001)\n",
        "\n",
        "history = train(model, train_loader, valid_loader, 100, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa3812926c3b47e6ae226295db075ebb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:0', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 3.227 valid loss:2.995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa9d1621572942b9a60262cdf8501cea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:1', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 2.795 valid loss:2.657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "274eb16fa0bb48f0ae9defb2371e5e15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:2', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 2.449 valid loss:2.400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "647fb23aba224a6d8ce75300108ebcb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:3', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 2.169 valid loss:2.162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af1421fb70f24d4eac48d046edc0c3d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:4', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.944 valid loss:1.974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d4ab08b3c1d48388c660b9e5db48ae1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:5', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.763 valid loss:1.822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f81b36b2f854723a68572b4c8cfb589",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:6', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.614 valid loss:1.703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "147a13a847f74c09bc48e1937ed68dc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:7', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.489 valid loss:1.613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93f594e41dea40b1acb4105c3dae0a40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:8', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.386 valid loss:1.513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1810b581f6014503a56ecfadd5172862",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:9', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.301 valid loss:1.449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a326cc827c23497384db13d81322ee66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:10', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.229 valid loss:1.387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fca2569c40f44379a73068afedc5a92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:11', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.167 valid loss:1.339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fca2cce9ac804800b4b3ce06701b482e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:12', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.114 valid loss:1.288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c825272a22fa4171a86d92a7dce31826",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:13', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.067 valid loss:1.250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50435fecf6fa4644ad7fc0577951d209",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:14', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.026 valid loss:1.218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77e637ff35c948249b06d46b58e38e6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:15', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.989 valid loss:1.186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b201791d01344b708c369e552db0e057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:16', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.962 valid loss:1.170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54f4343c4aaf4722abd0296edc78fa41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:17', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.933 valid loss:1.142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddbe21cb2a074b6195a1249dc869f7f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:18', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.911 valid loss:1.124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8a02dc4810c423d8f18cf89a4afc65a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:19', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.889 valid loss:1.108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e7809350da498c8635e4b876794ba1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:20', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.871 valid loss:1.088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87a79bd2b771478bbf4199d15cafa5a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:21', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.852 valid loss:1.079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "249ebe3416a4438aa03bc9d55673fe3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:22', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.837 valid loss:1.064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc6cf8b64db4483b5b2bf23e7432190",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:23', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.825 valid loss:1.063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29f8964e1aa34d788ec030094e5d8701",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:24', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.810 valid loss:1.039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b506d3d75c94df18bd09493bfcdab51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:25', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.802 valid loss:1.035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "525aa1f9622e41f9b18ca7ef5f97ca11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:26', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.790 valid loss:1.026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa5f7efbfd2146ecac4a7ece34aeeba0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:27', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.781 valid loss:1.020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "430e1047e69148eaa391c571da516c7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:28', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.772 valid loss:1.011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6079bdcfb2e438c907ad1aa646c3257",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:29', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.766 valid loss:1.009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "349bdfbeccd046029e28cc0280a836eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:30', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.757 valid loss:1.002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a000827c0fcf4693b6a21331850e8201",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:31', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.753 valid loss:0.996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8ea30024fdc4c958043be448202bac0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:32', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.746 valid loss:0.991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fc23bb8b02e43e0bd687d168017ba8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:33', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.740 valid loss:0.989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43b918f918ed48f0be2224c562914388",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:34', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.735 valid loss:0.986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f085f04995384eeeba55d60d811c5230",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:35', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.731 valid loss:0.979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d0eb996f76b4821a7047e7a45856bde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:36', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.728 valid loss:0.978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2e7ce8f0ae94a1d8b9f7087b8c61ad3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:37', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.722 valid loss:0.973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf369ae5f8f14f92b05a47bab6d26f9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:38', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.719 valid loss:0.969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed288e6fd04c48a7821e92b81ae517e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:39', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.715 valid loss:0.970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03eb2e802b744befa5efec87f8b14867",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:40', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.715 valid loss:0.968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1408a12fdab047938933330ec0203c78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:41', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.712 valid loss:0.967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc3e4cc01c0440ef9c04124f1759595f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:42', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.710 valid loss:0.964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8908ecc5dba54a24b9424d164e8b1d20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:43', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.707 valid loss:0.961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18df52b0b32749b8833315b9a5d944a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:44', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.704 valid loss:0.966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc468dab3bda48dd89b5da4da2fcb25d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:45', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.703 valid loss:0.964\n",
            "early stopping! best valid loss: 0.961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3DSgwtNGp8c",
        "colab_type": "code",
        "outputId": "4e2bbb4d-0eb3-449a-86f5-63fda774b2c9",
        "colab": {}
      },
      "source": [
        "plt.plot(np.arange(len(history['train'])), history['train'], label='train')\n",
        "plt.plot(np.arange(len(history['valid'])), history['valid'], label='valid')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1a1877b550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB9pKIvrGp8e",
        "colab_type": "code",
        "outputId": "90cb695f-c781-4008-d308-4b7b041e4b4a",
        "colab": {}
      },
      "source": [
        "y_pred = predict(model, test_loader)\n",
        "metrics.accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/denaas/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7947424322889007"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sVzCYntGp8g",
        "colab_type": "text"
      },
      "source": [
        "### What is the cross-entropy loss of uniformly random guessing classifier for this task? [0.5 point]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxZfJ7eCGp8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekliCifeGp8j",
        "colab_type": "text"
      },
      "source": [
        "### What is the accuracy of constant prediction classifier for this task? [0.5 point]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPDpjN_WGp8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}