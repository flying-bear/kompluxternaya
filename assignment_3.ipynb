{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flying-bear/kompluxternaya/blob/master/assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THlw8AQ5Gp7-",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "1. Implement Logistic Regression with Stochastic Gradient Decent using numpy\n",
        "1. Implement Logistic Regression with early stopping using pytorch\n",
        "\n",
        "Additional readings:\n",
        "1. https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html\n",
        "1. https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmmeezcRGp8C",
        "colab_type": "code",
        "outputId": "44073601-139b-40f0-c0bd-63b79fad9366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"error\")\n",
        "\n",
        "# retrieve dataset\n",
        "data = fetch_20newsgroups()\n",
        "\n",
        "\n",
        "X_train = data['data']\n",
        "y_train = data['target']\n",
        "\n",
        "tfidf = TfidfVectorizer(max_df=0.5, min_df=10)\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "\n",
        "test_data = fetch_20newsgroups(subset='test')\n",
        "X_test = tfidf.transform(test_data['data'])\n",
        "y_test = test_data['target']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj2mr-g9Gp8G",
        "colab_type": "text"
      },
      "source": [
        "## 1 Binary Logistic Regression\n",
        "$\\{(x_i, y_i)\\}_{i=1}^N$, $y \\in \\{0,1\\}$\n",
        "$$ z = Xw + b $$\n",
        "\n",
        "$$p(y=1 | x) = \\sigma(z) = \\frac 1 {1 + e^{-z}}$$\n",
        "\n",
        "$$ L_{batch} = - \\frac 1 {|batch|} \\sum_{i \\in batch}^N [ y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i)) ] + \\frac \\lambda 2 w^T w$$\n",
        "\n",
        "Stochastic Gradient Decent for logreg:\n",
        "1. init w ~ random N(0,1), b = 0\n",
        "1. for epoch = 1..n_epochs:\n",
        "    * shuffle dataset\n",
        "    * for every batch:\n",
        "        * $w^{(t)} \\leftarrow w^{(t-1)} - \\alpha \\nabla_{w} L_{batch}(w^{(t-1)},b^{(t-1)})$\n",
        "        * $b^{(t)} \\leftarrow b^{(t-1)} - \\alpha \\nabla_{b} L_{batch}(w^{(t-1)},b^{(t-1)})$\n",
        "        \n",
        "$w$ - weights  \n",
        "$b$ - biases  \n",
        "$\\alpha$ - learning rate\n",
        "\n",
        "Hint:\n",
        "$$\\nabla_w L = \\frac {\\partial L} {\\partial \\sigma} \\frac {\\partial \\sigma} {\\partial z} \\frac {\\partial z} {\\partial w} + \\frac {\\partial (\\frac \\lambda 2 w^T w)} {\\partial w} $$\n",
        "$$\\nabla_b L = \\frac {\\partial L} {\\partial \\sigma} \\frac {\\partial \\sigma} {\\partial z} \\frac {\\partial z} {\\partial b} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO3tY0n7Gp8H",
        "colab_type": "code",
        "outputId": "1cc11593-284e-4382-8340-86f1d0e1bb4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# make dataset for binary classification\n",
        "\n",
        "X_train_bin = X_train[y_train < 2]\n",
        "y_train_bin = y_train[y_train < 2]\n",
        "\n",
        "X_test_bin = X_test[y_test < 2]\n",
        "y_test_bin = y_test[y_test < 2]\n",
        "\n",
        "y_train_bin.shape, y_test_bin.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1064,), (708,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM9I_3xjT-dk",
        "colab_type": "code",
        "outputId": "7774d547-8161-45ce-9723-08958b8b1afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(f'X shape: {X_train_bin.shape}')\n",
        "print(f'y shape: {y_train_bin.shape}')\n",
        "w_test_size = np.random.randn(X_train_bin.shape[1])\n",
        "print(f'w shape: {w_test_size.shape}')\n",
        "print(f'Xw shape: {(X_train_bin.dot(w_test_size)).shape}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (1064, 15566)\n",
            "y shape: (1064,)\n",
            "w shape: (15566,)\n",
            "Xw shape: (1064,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwRvEA7FNAuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRY TO IMPLEMENT LOSS on some 64 datapoints\n",
        "\n",
        "llambda = 1\n",
        "test_batch_X = X_train_bin[64:128, :]\n",
        "test_batch_y = y_train_bin[64:128]\n",
        "w = np.random.randn(test_batch_X.shape[1])\n",
        "b = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLm5RnH2z6aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_loss(batch_X, batch_y, w, b, llambda, batch_size):\n",
        "  z = batch_X.dot(w) + b\n",
        "  sigm = 1 / (1 + np.exp(-z))\n",
        "  loss = (-1/batch_size) * (np.sum(batch_y*np.log(sigm) + (1-batch_y)*(np.log(1-sigm)))).item() + (llambda/2) * w.transpose().dot(w)\n",
        "  return loss, sigm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEN0XYuQ0IbK",
        "colab_type": "code",
        "outputId": "52ed00b8-b050-4411-91de-2ea4e5896b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss, test_sigm = count_loss(test_batch_X, test_batch_y, w, b, llambda, test_batch_y.shape[0])\n",
        "test_loss"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7914.598089124795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IanngQfVr8T7",
        "colab_type": "text"
      },
      "source": [
        "**Gradient formulae**\n",
        "\n",
        "$$\\nabla_w L = \\frac {\\partial L} {\\partial \\sigma} \\frac {\\partial \\sigma} {\\partial z} \\frac {\\partial z} {\\partial w} + \\frac {\\partial (\\frac \\lambda 2 w^T w)} {\\partial w} $$\n",
        "$$\\nabla_b L = \\frac {\\partial L} {\\partial \\sigma} \\frac {\\partial \\sigma} {\\partial z} \\frac {\\partial z} {\\partial b} $$\n",
        "\n",
        "Посчитаем части формул\n",
        "$$ L_{batch} = - \\frac 1 {|batch|} \\sum_{i \\in batch}^N [ y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i)) ] + \\frac \\lambda 2 w^T w$$\n",
        "\n",
        "$$\\frac {\\partial} {\\partial \\sigma}[y \\log \\sigma(z) + (1 - y) \\log (1 - \\sigma(z))] = \\frac {y}{\\sigma} + \\frac {-1 \\cdot (1 - y)}{1 - \\sigma} = \\frac {y(1 - \\sigma) - \\sigma(1 - y)} {\\sigma(1 - \\sigma)} = \\frac {y - \\sigma y - \\sigma + \\sigma y}{\\sigma(1 - \\sigma)} = \\frac {y - \\sigma}{\\sigma(1 - \\sigma)}$$\n",
        "\n",
        "$$\\frac {\\partial L} {\\partial \\sigma} = -\\frac {1} {|batch|} \\sum_{i \\in batch}^N \\frac {y_i - \\sigma(z_i)} {\\sigma (1 - \\sigma(z_i))}$$\n",
        "\n",
        "$$\\frac {\\partial \\sigma} {\\partial z} = \\frac 1 {1 + e^{-z}} \\frac {e^{-z}} {(1 + e^{-z})^2} ={\\sigma}({1 - \\sigma})$$\n",
        "\n",
        "$$ \\frac {\\partial z} {\\partial w} = X^T $$\n",
        "\n",
        "$$ \\frac {\\partial (\\frac \\lambda 2 w^T w)} {\\partial w} = \\lambda w$$\n",
        "\n",
        "$$ \\frac {\\partial z} {\\partial b} = 1 $$\n",
        "Identity matrix\n",
        "\n",
        "\n",
        "Соберём вместе\n",
        "\n",
        "$$\\nabla_w L = \\frac {- \\sigma (1 - \\sigma) X^T} {|batch|} \\sum_{i \\in batch}^N [\\frac {y_i - \\sigma_i} {\\sigma_i (1 - \\sigma_i)}] +  \\lambda w$$\n",
        "$$\\nabla_b L = \\frac {-\\sigma (1 - \\sigma)} {|batch|} \\sum_{i \\in batch}^N [\\frac {y_i - \\sigma_i} {\\sigma_i (1 - \\sigma_i)}]$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjgsEj7Ercgz",
        "colab_type": "code",
        "outputId": "061ce84e-cfba-4689-f8f3-baedf45235e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# TRY TO IMPLEMENT GRADIENT\n",
        "batch_size = test_batch_y.shape[0]\n",
        "test_dL_dsigm = (-1/batch_size) * np.sum((test_batch_y - test_sigm)/(test_sigm * (1-test_sigm)))\n",
        "test_dsigm_dz = test_sigm * (1 - test_sigm)\n",
        "test_grad_w = test_dL_dsigm * test_batch_X.transpose().dot(test_dsigm_dz) + llambda * w\n",
        "test_grad_b = test_dL_dsigm * test_dsigm_dz.dot(np.ones(test_dsigm_dz.shape[0]))\n",
        "\n",
        "test_grad_w.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15566,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4-KnRhSJ8pU",
        "colab_type": "code",
        "outputId": "60df298a-0680-475f-e8ad-ad0ff49cff45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# COMPARE LOSS BEFORE AND AFTER SGD\n",
        "print(count_loss(test_batch_X, test_batch_y, w, b, llambda, test_batch_y.shape[0])[0])\n",
        "print(count_loss(test_batch_X, test_batch_y, w-0.0001*test_grad_w, b-0.0001*test_grad_b, llambda, test_batch_y.shape[0])[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7914.598089124795\n",
            "7913.015275152144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImY3_9veLPZr",
        "colab_type": "text"
      },
      "source": [
        "[gradient checking](https://datascience-enthusiast.com/DL/Improving_DeepNeural_Networks_Gradient_Checking.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJehL2W4Gp8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class LogRegNumpy(ClassifierMixin):\n",
        "    def __init__(self, llambda=1, lr=0.0001, batch_size=32, n_epochs=100):\n",
        "        \"\"\"\n",
        "        llambda: regularization strength\n",
        "        lr: learning rate\n",
        "        \"\"\"\n",
        "        self.w = None\n",
        "        self.b = 0\n",
        "        self.llambda = llambda\n",
        "        self.n_epochs = n_epochs\n",
        "        self.lr = lr\n",
        "        self.history = []\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(z):\n",
        "      return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def batch_loss(self, batch_X, batch_y, w, b, llambda, batch_size):\n",
        "      \"\"\"\n",
        "      calculates loss over a batch with regularization\n",
        "      :param batch_X: batch data, np.ndarray of shape (batch size, number of features)\n",
        "      :param batch_y: batch labels, np.ndarray of shape (batch size,)\n",
        "      :param w: weigths matrix, np.ndarray of shape (number of features,)\n",
        "      :param b: bias, a number (int or float)\n",
        "      :param llambda: regularizartion strength, a number (int or float)\n",
        "      :param batch_size: batch size, int\n",
        "\n",
        "      :return loss: loss, float\n",
        "      :return sigm: predictions, np.ndarray of shape (batch size,)\n",
        "      :return z: sigmoid logit, np.ndarray of shape (batch size,)\n",
        "      \"\"\"\n",
        "      z = batch_X.dot(w) + b\n",
        "      # if np.isnan(np.sum(z)):\n",
        "      #   return\n",
        "      sigm = self.sigmoid(z)\n",
        "      reg = (llambda/2) * w.transpose().dot(w)\n",
        "      loss = (-1/batch_size) * (np.sum(batch_y*np.log(sigm) + (1-batch_y)*(np.log(1-sigm)))).item() + reg\n",
        "      return loss, sigm, z\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.w = np.random.randn(X.shape[1])\n",
        "        self.b = 0\n",
        "        \n",
        "        for epoch in range(self.n_epochs):\n",
        "            \n",
        "            # random permutation over indices of dataset\n",
        "            batch_indices = np.random.permutation(len(y))\n",
        "            \n",
        "            for j in range(0, len(y), self.batch_size):\n",
        "                batch_idx = batch_indices[j:j+self.batch_size]\n",
        "                batch_X = X[batch_idx]\n",
        "                batch_y = y[batch_idx]\n",
        "            \n",
        "                # forward pass\n",
        "                # <TODO> [1 point] calculate batch loss\n",
        "                loss, sigm, z = self.batch_loss(batch_X, batch_y, self.w, self.b, self.llambda, self.batch_size)\n",
        "\n",
        "                # backward pass\n",
        "                # <TODO> [2 points] calculate batch gradients \n",
        "                dL_dsigm = (-1/self.batch_size) * np.sum((batch_y - sigm)/(sigm * (1-sigm)))\n",
        "                dsigm_dz = sigm * (1 - sigm)\n",
        "                grad_w = dL_dsigm * batch_X.transpose().dot(dsigm_dz) + self.llambda * self.w\n",
        "                grad_b = dL_dsigm * dsigm_dz.dot(np.ones(dsigm_dz.shape[0]))\n",
        "\n",
        "                # # check gradient of b\n",
        "                # epsilon = 1e-7  # (is this epsilon small enough?)\n",
        "                # b_minus_step_loss = self.batch_loss(batch_X, batch_y, self.w, self.b-epsilon, self.llambda, self.batch_size)[0]\n",
        "                # b_plus_step_loss = self.batch_loss(batch_X, batch_y, self.w, self.b+epsilon, self.llambda, self.batch_size)[0]\n",
        "                # approximate_grad_b = (b_plus_step_loss - b_minus_step_loss)/ (2*epsilon)\n",
        "                # print(grad_b, approximate_grad_b)\n",
        "                # b_difference = abs(grad_b-approximate_grad_b)/(abs(grad_b)+abs(approximate_grad_b))\n",
        "                # assert b_difference < epsilon, f\"approximated gradient for b differs from calculated by {b_difference}\"\n",
        "\n",
        "                # # check gradient of w\n",
        "                # param_num = self.w.shape[0]\n",
        "                # w_plus_step_loss = np.zeros(param_num)\n",
        "                # w_minus_step_loss = np.zeros(param_num)\n",
        "                # approximate_grad_w = np.zeros(param_num)\n",
        "                # for i in range(param_num):\n",
        "                #   check_w_plus = np.copy(self.w)\n",
        "                #   check_w_plus[i] += epsilon\n",
        "                #   w_plus_step_loss[i] = self.batch_loss(batch_X, batch_y, check_w_plus, self.b, self.llambda, self.batch_size)[0]\n",
        "\n",
        "                #   check_w_minus = np.copy(self.w)\n",
        "                #   check_w_minus[i] -= epsilon\n",
        "                #   w_minus_step_loss[i] = self.batch_loss(batch_X, batch_y, check_w_minus, self.b, self.llambda, self.batch_size)[0]\n",
        "\n",
        "                #   approximate_grad_w[i] = (w_plus_step_loss[i] - w_minus_step_loss[i]) / (2 * epsilon)\n",
        "                # w_difference = np.linalg.norm(grad_w - approximate_grad_w) / (np.linalg.norm(grad_w) + np.linalg.norm(approximate_grad_w))\n",
        "                # assert w_difference < epsilon,  f\"approximated gradient for w differs from calculated by {w_difference}\"\n",
        "\n",
        "                # SGD optimization step\n",
        "                # <TODO> [1 point]\n",
        "                self.w -= self.lr * grad_w\n",
        "                self.b -= self.lr * grad_b\n",
        "                \n",
        "                self.history.append(loss)\n",
        "        \n",
        "        return self \n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        # <TODO> [1 point] calculate p(y=1 | x)\n",
        "        z = X.dot(self.w) + self.b\n",
        "        p = self.sigmoid(z)\n",
        "        return p\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return (self.predict_proba(X) > 0.5).astype(np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuOLVFcscTuU",
        "colab_type": "text"
      },
      "source": [
        "**I think that learning rate of 3 doesn't make sense, neither does llambda of 0.001. However, the reverse does. So I swapped them.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRT02B8AcCxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "dff67fa5-714b-467d-cc62-d32c7c9c65cb"
      },
      "source": [
        "model = LogRegNumpy(llambda = 3, lr=0.001, batch_size=128, n_epochs=100)\n",
        "model.fit(X_train_bin, y_train_bin)\n",
        "print('test auc', metrics.roc_auc_score(y_test_bin, model.predict_proba(X_test_bin)))\n",
        "\n",
        "plt.plot(np.arange(len(model.history)), model.history)\n",
        "plt.xlabel('iters')\n",
        "plt.ylabel('train loss')\n",
        "plt.title('Train loss');"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test auc 0.6872214745630223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl7PqSm-Gp8N",
        "colab_type": "text"
      },
      "source": [
        "# Multinomial Logistic Regression using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2NVfSdgGp8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5a0uBhBGp8Q",
        "colab_type": "text"
      },
      "source": [
        "###  [1 point] implement linear model $Z = XW + b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TUHTCONGp8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogRegNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_features, n_classes):\n",
        "        super(LogRegNN, self).__init__()\n",
        "        \n",
        "        # create tensor of weights and tensor of biases\n",
        "        # initialize tensors from N(0,1) \n",
        "        # W has shape (n_features, n_classes)\n",
        "        # b has shape (n_classes,)\n",
        "        self.W = nn.Parameter(torch.randn(n_features, n_classes))\n",
        "        self.b = nn.Parameter(torch.randn(n_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In this method we implement connections between neural network weights\n",
        "        x: batch feature matrix\n",
        "        returns: probability logits\n",
        "        \"\"\"\n",
        "        # <TODO> implement linear model \n",
        "        x_dense = torch.from_numpy(x.todense())\n",
        "        result = torch.mm(x_dense, self.W) + self.b\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IchAOQJHAFdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "3fbb2ace-4a7f-49c2-fe6e-43ff6bb35f7a"
      },
      "source": [
        "model = LogRegNN(X_train.shape[1], 20)\n",
        "model(test_batch_X)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-d706a180e0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogRegNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-e58ef3755f73>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# <TODO> implement linear model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for argument #2 'mat2' in call to _th_mm"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOTIaY_ZGp8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(model, batch_x, batch_y):\n",
        "    # set NN model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass\n",
        "    pred = model(batch_x)\n",
        "    # cross-entropy loss\n",
        "    loss = criterion(pred, batch_y)\n",
        "    # calculate gradients\n",
        "    loss.backward()\n",
        "    # make optimization step\n",
        "    optimizer.step()\n",
        "    \n",
        "    # return batch loss\n",
        "    return loss.data.detach().item()\n",
        "\n",
        "def eval_batch(model, batch_x, batch_y):\n",
        "    # set NN model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # forward pass\n",
        "        pred = model(batch_x)\n",
        "        # cross-entropy loss\n",
        "        loss = criterion(pred, batch_y)\n",
        "\n",
        "    # return batch loss\n",
        "    return loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcZKcQ1BGp8V",
        "colab_type": "text"
      },
      "source": [
        "### [2 points] implement early stopping using early_stopping_patience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUUpVo6x-vp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import reduce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmYimmWXGp8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, valid_loader, n_epochs, early_stopping_patience=5):\n",
        "    \"\"\"\n",
        "    early_stopping_patience - number of consecutive epochs of growing validation loss to wait\n",
        "    \"\"\"\n",
        "    history = {'train': [], 'valid': []}\n",
        "\n",
        "    # <TODO> implement early stopping using early_stopping_patience\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        # iterate over batches\n",
        "        for batch_x, batch_y in tqdm(train_loader, desc=f'epoch:{epoch}', leave=True):\n",
        "\n",
        "            loss = train_batch(model, batch_x, batch_y)\n",
        "            epoch_train_loss += loss\n",
        "\n",
        "        # average loss for epoch\n",
        "        epoch_train_loss /= len(train_loader)\n",
        "        history['train'].append(epoch_train_loss)\n",
        "        \n",
        "        epoch_valid_loss = 0\n",
        "        for batch_x, batch_y in valid_loader:\n",
        "            loss = eval_batch(model, batch_x, batch_y)\n",
        "            epoch_valid_loss += loss\n",
        "            \n",
        "        epoch_valid_loss /= len(valid_loader)\n",
        "        print(f'train loss: {epoch_train_loss:.3f} valid loss:{epoch_valid_loss:.3f}')\n",
        "        history['valid'].append(epoch_valid_loss)\n",
        "        \n",
        "        # <TODO> implement early stopping using early_stopping_patience\n",
        "        if len(history['valid']) > early_stopping_patience:\n",
        "          if reduce(lambda x, y: x < y, history['valid'][-early_stopping_patience:]):\n",
        "            return history \n",
        "\n",
        "    return history "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv0-cG9qGp8X",
        "colab_type": "text"
      },
      "source": [
        "### predict hard labels [1 point]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7lhvAsHGp8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, test_loader):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    result = []\n",
        "    with torch.no_grad():\n",
        "        for batch_x in test_loader:\n",
        "            # <TODO> predict hard labels\n",
        "            pred = \n",
        "            result.append(pred)\n",
        "    return np.concatenate(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-pN2aPbGp8a",
        "colab_type": "text"
      },
      "source": [
        "DataLoader implements iteration over batches and shuffling\n",
        "\n",
        "L2 regularization coef is embedded into SGD.weight_decay: \n",
        "\n",
        "1. $w^{(t-1)} \\leftarrow w^{(t-2)} - \\alpha \\lambda w^{(t-2)} $  \n",
        "1. $w^{(t)} \\leftarrow w^{(t-1)} - \\alpha \\nabla_{w} L(w^{(t-1)}) $\n",
        "\n",
        "here   \n",
        "$\\alpha$ - learning rate  \n",
        "$\\lambda$ - weight-decay = L2 regularization coef"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbBkftMcGp8a",
        "colab_type": "code",
        "outputId": "a8013d27-5fd1-4589-c19c-4c260771da3e",
        "colab": {}
      },
      "source": [
        "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_train, y_train, stratify=y_train,\n",
        "                                                      shuffle=True, test_size=0.2, random_state=42)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(torch.tensor(X_train2.todense()).float(), torch.tensor(y_train2).long()), \n",
        "                          batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(TensorDataset(torch.tensor(X_valid2.todense()).float(), torch.tensor(y_valid2).long()), \n",
        "                          batch_size=batch_size)\n",
        "test_loader = DataLoader(torch.tensor(X_test.todense()).float(), \n",
        "                          batch_size=batch_size)\n",
        "\n",
        "model = LogRegNN(X_train.shape[1], 20)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# L2 regularization is embeded in \n",
        "optimizer = optim.SGD(model.parameters(), lr=10.0, weight_decay=0.0001)\n",
        "\n",
        "history = train(model, train_loader, valid_loader, 100, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa3812926c3b47e6ae226295db075ebb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:0', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 3.227 valid loss:2.995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa9d1621572942b9a60262cdf8501cea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:1', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 2.795 valid loss:2.657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "274eb16fa0bb48f0ae9defb2371e5e15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:2', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 2.449 valid loss:2.400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "647fb23aba224a6d8ce75300108ebcb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:3', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 2.169 valid loss:2.162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af1421fb70f24d4eac48d046edc0c3d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:4', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.944 valid loss:1.974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d4ab08b3c1d48388c660b9e5db48ae1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:5', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.763 valid loss:1.822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f81b36b2f854723a68572b4c8cfb589",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:6', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.614 valid loss:1.703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "147a13a847f74c09bc48e1937ed68dc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:7', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.489 valid loss:1.613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93f594e41dea40b1acb4105c3dae0a40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:8', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.386 valid loss:1.513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1810b581f6014503a56ecfadd5172862",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:9', max=36, style=ProgressStyle(description_width='init…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.301 valid loss:1.449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a326cc827c23497384db13d81322ee66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:10', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.229 valid loss:1.387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fca2569c40f44379a73068afedc5a92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:11', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.167 valid loss:1.339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fca2cce9ac804800b4b3ce06701b482e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:12', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.114 valid loss:1.288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c825272a22fa4171a86d92a7dce31826",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:13', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.067 valid loss:1.250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50435fecf6fa4644ad7fc0577951d209",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:14', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 1.026 valid loss:1.218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77e637ff35c948249b06d46b58e38e6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:15', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.989 valid loss:1.186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b201791d01344b708c369e552db0e057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:16', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.962 valid loss:1.170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54f4343c4aaf4722abd0296edc78fa41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:17', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.933 valid loss:1.142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddbe21cb2a074b6195a1249dc869f7f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:18', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.911 valid loss:1.124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8a02dc4810c423d8f18cf89a4afc65a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:19', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.889 valid loss:1.108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e7809350da498c8635e4b876794ba1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:20', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.871 valid loss:1.088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87a79bd2b771478bbf4199d15cafa5a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:21', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.852 valid loss:1.079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "249ebe3416a4438aa03bc9d55673fe3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:22', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.837 valid loss:1.064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc6cf8b64db4483b5b2bf23e7432190",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:23', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.825 valid loss:1.063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29f8964e1aa34d788ec030094e5d8701",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:24', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.810 valid loss:1.039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b506d3d75c94df18bd09493bfcdab51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:25', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.802 valid loss:1.035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "525aa1f9622e41f9b18ca7ef5f97ca11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:26', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.790 valid loss:1.026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa5f7efbfd2146ecac4a7ece34aeeba0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:27', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.781 valid loss:1.020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "430e1047e69148eaa391c571da516c7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:28', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.772 valid loss:1.011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6079bdcfb2e438c907ad1aa646c3257",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:29', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.766 valid loss:1.009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "349bdfbeccd046029e28cc0280a836eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:30', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.757 valid loss:1.002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a000827c0fcf4693b6a21331850e8201",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:31', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.753 valid loss:0.996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8ea30024fdc4c958043be448202bac0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:32', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.746 valid loss:0.991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fc23bb8b02e43e0bd687d168017ba8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:33', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.740 valid loss:0.989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43b918f918ed48f0be2224c562914388",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:34', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.735 valid loss:0.986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f085f04995384eeeba55d60d811c5230",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:35', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.731 valid loss:0.979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d0eb996f76b4821a7047e7a45856bde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:36', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.728 valid loss:0.978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2e7ce8f0ae94a1d8b9f7087b8c61ad3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:37', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.722 valid loss:0.973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf369ae5f8f14f92b05a47bab6d26f9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:38', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.719 valid loss:0.969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed288e6fd04c48a7821e92b81ae517e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:39', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.715 valid loss:0.970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03eb2e802b744befa5efec87f8b14867",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:40', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.715 valid loss:0.968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1408a12fdab047938933330ec0203c78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:41', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.712 valid loss:0.967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc3e4cc01c0440ef9c04124f1759595f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:42', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.710 valid loss:0.964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8908ecc5dba54a24b9424d164e8b1d20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:43', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.707 valid loss:0.961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18df52b0b32749b8833315b9a5d944a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:44', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.704 valid loss:0.966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc468dab3bda48dd89b5da4da2fcb25d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch:45', max=36, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train loss: 0.703 valid loss:0.964\n",
            "early stopping! best valid loss: 0.961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3DSgwtNGp8c",
        "colab_type": "code",
        "outputId": "4e2bbb4d-0eb3-449a-86f5-63fda774b2c9",
        "colab": {}
      },
      "source": [
        "plt.plot(np.arange(len(history['train'])), history['train'], label='train')\n",
        "plt.plot(np.arange(len(history['valid'])), history['valid'], label='valid')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1a1877b550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB9pKIvrGp8e",
        "colab_type": "code",
        "outputId": "90cb695f-c781-4008-d308-4b7b041e4b4a",
        "colab": {}
      },
      "source": [
        "y_pred = predict(model, test_loader)\n",
        "metrics.accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/denaas/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7947424322889007"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sVzCYntGp8g",
        "colab_type": "text"
      },
      "source": [
        "### What is the cross-entropy loss of uniformly random guessing classifier for this task? [0.5 point]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxZfJ7eCGp8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekliCifeGp8j",
        "colab_type": "text"
      },
      "source": [
        "### What is the accuracy of constant prediction classifier for this task? [0.5 point]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPDpjN_WGp8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}